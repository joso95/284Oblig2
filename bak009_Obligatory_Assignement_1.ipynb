{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as nb\n",
    "import pandas as pd\n",
    "import pandas_profiling\n",
    "import nltk as nltk\n",
    "import re\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import sent_tokenize\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leser inn via pandas read\n",
    "data_frame = pd.read_csv(\"tweets.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitter dataframen til 2 frames\n",
    "training_data_frame, test_data_frame = train_test_split(data_frame, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setter alt til lower\n",
    "training_data_frame.loc[:, ('text')] = training_data_frame.loc[:, ('text')].str.lower()\n",
    "#print(training_data_frame[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fjerner alt utenom tekst\n",
    "training_data_frame.loc[:, ('text')]=training_data_frame.loc[:, ('text')].replace({\"[^a-zA-Z ]\":''}, regex = True)\n",
    "#print(training_data_frame.loc[:, ('text')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenizer alle ordene i tweets.\n",
    "training_data_frame.loc[:, ('text')] = training_data_frame.loc[:, ('text')].apply(nltk.word_tokenize)\n",
    "#NB: må kjøres før stopwords er applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applier stop words\n",
    "stop_words = set(stopwords.words('english')) \n",
    "#training_data_frame.loc[:, ('text')] = training_data_frame.loc[:, ('text')].apply(lambda x: [item for item in x if item not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Denne kalles på en tweet som kommer inn i min naive bayes og renser tweeten.\n",
    "def the_cleaner(tweet):\n",
    "    #if type(tweet) == list:\n",
    "        #return\n",
    "    tokens = tweet.split()\n",
    "    tokens = [t.translate(str.maketrans('', '', punctuation)) for t in tokens]\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    tokens = [word.lower() for word in tokens]\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lager 3 lister med positive, neutrale og negative tweets.\n",
    "pos_tweets = []\n",
    "neut_tweets = []\n",
    "neg_tweets = []\n",
    "\n",
    "for i in range(len(training_data_frame)):\n",
    "    if (training_data_frame.iloc[i][\"airline_sentiment\"] == \"positive\"):\n",
    "        pos_tweets.append(training_data_frame.iloc[i][\"text\"])\n",
    "        \n",
    "for i in range(len(training_data_frame)):\n",
    "    if (training_data_frame.iloc[i][\"airline_sentiment\"] == \"neutral\"):\n",
    "        neut_tweets.append(training_data_frame.iloc[i][\"text\"])\n",
    "        \n",
    "for i in range(len(training_data_frame)):\n",
    "    if (training_data_frame.iloc[i][\"airline_sentiment\"] == \"negative\"):\n",
    "        neg_tweets.append(training_data_frame.iloc[i][\"text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kalkuler forekomst av ord i de forksjellige listene\n",
    "def freq_calc(incoming_list):\n",
    "    local_dict = {}\n",
    "    for x in incoming_list:\n",
    "        for y in x:\n",
    "            if y not in local_dict.keys():\n",
    "                local_dict[y] = 1\n",
    "            else:\n",
    "                local_dict[y] += 1\n",
    "    return local_dict\n",
    "\n",
    "pos_freq = freq_calc(pos_tweets) \n",
    "neut_freq = freq_calc(neut_tweets)\n",
    "neg_freq = freq_calc(neg_tweets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kalkulerer sannsynligheten for at et ord innen for positive, neutral eller negative.\n",
    "def occurance_sentiments(word_freq):\n",
    "    occurance_list = {}\n",
    "    for x in word_freq.keys():\n",
    "        temp = word_freq[x]/sum(word_freq.values())\n",
    "        occurance_list[x] = temp\n",
    "    return occurance_list\n",
    "\n",
    "#Her lages listene for forekomst\n",
    "pos_occurance = occurance_sentiments(pos_freq)\n",
    "neut_occurance = occurance_sentiments(neut_freq)\n",
    "neg_occurance = occurance_sentiments(neg_freq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finner ut hvor sannsynlig det er at en tweet er positiv, neutral eller negative.\n",
    "def probability_of_tweets_sentiment(total_tweets, sentiment_amount):\n",
    "    return sentiment_amount/total_tweets \n",
    "\n",
    "#Her lagres verdiene\n",
    "pos_probability = probability_of_tweets_sentiment(training_data_frame.loc[:, ('text')].count(), len(pos_tweets))\n",
    "neut_probability = probability_of_tweets_sentiment(training_data_frame.loc[:, ('text')].count(), len(neut_tweets))\n",
    "neg_probability = probability_of_tweets_sentiment(training_data_frame.loc[:, ('text')].count(), len(neg_tweets))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Her lages en dictionary med unike ord og forekomsten av det i alle tweets\n",
    "word_freq = {}\n",
    "for tweet in training_data_frame.loc[:, ('text')]:\n",
    "    for word in tweet:\n",
    "        if word not in word_freq.keys():\n",
    "            word_freq[word] = 1\n",
    "        else:\n",
    "            word_freq[word] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Her beregens ordets forekomst i alle sentimenter\n",
    "def occurance_in_all_sentiments(occurance_list):\n",
    "    oias = {}\n",
    "    for word in occurance_list:\n",
    "        if word not in oias:\n",
    "            oias[word] = occurance_list[word]/sum(word_freq.values())\n",
    "    return oias\n",
    "\n",
    "total_occurance_list = occurance_in_all_sentiments(word_freq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_scratch_naive_bayes(tweet):\n",
    "    temp = the_cleaner(tweet) #rense metode for tweeten\n",
    "    pos_bayes = 0\n",
    "    neut_bayes = 0\n",
    "    neg_bayes = 0\n",
    "    pos_neut_neg_value = 0\n",
    "    occ_value = 0\n",
    "    what_to_return = []\n",
    "    \n",
    "    for word in temp:\n",
    "        if word not in word_freq:\n",
    "            word = 1/len(word_freq.keys())\n",
    "            #Task 8: hvis ordet ikke finnes i vokabulæret så vil den bli omgjort til 1 delt på lengden av unike ord\n",
    "        for positive_word in pos_occurance:\n",
    "            #Her matcher vi ordet med dens forekomst i positive tweets \n",
    "            if word == positive_word:\n",
    "                pos_bayes += (pos_occurance[word] * pos_probability) / total_occurance_list[word]\n",
    "                #Her regnes ut naive bayes for ordet i en positiv sammenheng, det samme gjøres for neutral og\n",
    "                #og negative i for løkkene under\n",
    "        \n",
    "        for neutral_word in neut_occurance:\n",
    "            if word == neutral_word:\n",
    "                neut_bayes += (neut_occurance[word] * neut_probability) / total_occurance_list[word]\n",
    "        \n",
    "        for negative_word in neg_occurance:\n",
    "            if word == negative_word:\n",
    "                neg_bayes += (neg_occurance[word] * neg_probability) / total_occurance_list[word]\n",
    "                #print(neg_occurance[word], neg_probability, total_occurance_list[word])\n",
    "    \n",
    "    what_to_return.append(pos_bayes/len(temp))\n",
    "    what_to_return.append(neut_bayes/len(temp))\n",
    "    what_to_return.append(neg_bayes/len(temp))\n",
    "    #Her deles de forskjellige summene vi får på lengden av tweeten og legges i en liste, det størte tallet\n",
    "    #vil ble valgt av if setningen under. Siden følgen av tallene alltid er positiv, neutral og negativ kan vi\n",
    "    #returne en string basert på posisjonen som blir returnert.\n",
    "    \n",
    "    if what_to_return.index(max(what_to_return))== 0: return \"positive\"\n",
    "    if what_to_return.index(max(what_to_return))== 1: return \"neutral\"\n",
    "    else: return \"negative\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accurcy score is: 0.7547814207650273\n"
     ]
    }
   ],
   "source": [
    "def score(test_data_frame):\n",
    "    outer_temp = []\n",
    "    total_score = 0\n",
    "    for i in range(len(test_data_frame)):\n",
    "        if (test_data_frame.iloc[i][\"airline_sentiment\"] == from_scratch_naive_bayes(test_data_frame.iloc[i][\"text\"])):\n",
    "            total_score += 1\n",
    "            #Her sammenlignes det som kommer tilbake fra bayes med det som står i sentimentet, og hvis det er likt\n",
    "            #så plusses det 1 på total_score. Scoren blir deretter delt på lengden av data_framen for å få\n",
    "            #en nøykatighets score.\n",
    "    return total_score/len(test_data_frame)\n",
    "        \n",
    "        \n",
    "#Her kalles score med test_data_frame.\n",
    "print(\"The accurcy score is: \" + str(score(test_data_frame)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter your desired tweethappy good yay i like\n",
      "Your bayes output is as follow: positive\n"
     ]
    }
   ],
   "source": [
    "#Task 9, this is a basic module that can take input.\n",
    "def tweet_input():\n",
    "    user_input = input(\"Please enter your desired tweet\")\n",
    "    output = from_scratch_naive_bayes(user_input)\n",
    "    print(\"Your bayes output is as follow: \"+output)\n",
    "    \n",
    "tweet_input()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_scratch_naive_bayes_with_explanation(tweet):\n",
    "    temp = the_cleaner(tweet) #rense metode for tweeten\n",
    "    pos_bayes = 0\n",
    "    neut_bayes = 0\n",
    "    neg_bayes = 0\n",
    "    pos_neut_neg_value = 0\n",
    "    occ_value = 0\n",
    "    what_to_return = []\n",
    "    induvidually_words = {}\n",
    "    \n",
    "    for word in temp:\n",
    "        if word not in word_freq:\n",
    "            word = 1/len(word_freq.keys())\n",
    "            \n",
    "        for positive_word in pos_occurance:\n",
    "            if word == positive_word:\n",
    "                pos_bayes += (pos_occurance[word] * pos_probability) / total_occurance_list[word]\n",
    "        \n",
    "        for neutral_word in neut_occurance:\n",
    "            if word == neutral_word:\n",
    "                neut_bayes += (neut_occurance[word] * neut_probability) / total_occurance_list[word]\n",
    "        \n",
    "        for negative_word in neg_occurance:\n",
    "            if word == negative_word:\n",
    "                neg_bayes += (neg_occurance[word] * neg_probability) / total_occurance_list[word]\n",
    "    \n",
    "    what_to_return.append(pos_bayes/len(temp))\n",
    "    what_to_return.append(neut_bayes/len(temp))\n",
    "    what_to_return.append(neg_bayes/len(temp))\n",
    "    \n",
    "    for i in range(len(what_to_return)):\n",
    "        if i == 0:\n",
    "            induvidually_words[\"positive naive bayes probablity\"]=what_to_return[i]\n",
    "        if i == 1:\n",
    "            induvidually_words[\"neutral naive bayes probablity\"]=what_to_return[i]\n",
    "        if i == 2:\n",
    "            induvidually_words[\"negative naive bayes probablity\"]=what_to_return[i]\n",
    "            \n",
    "    if what_to_return.index(max(what_to_return))== 0: return \"positive\", induvidually_words\n",
    "    if what_to_return.index(max(what_to_return))== 1: return \"neutral\", induvidually_words\n",
    "    else: return \"negative\", induvidually_words\n",
    "    #Dette er en kopi av min første naive bayes metode, bare at den returnerer mer informasjon om en tweet.\n",
    "    #Den returnerer naive bayes sansynligheten innen for positive, neutral og negative og i tilegg hva svaret den\n",
    "    #den gir er."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('negative', {'positive naive bayes probablity': 0.04017800351063945, 'neutral naive bayes probablity': 0.05825095002325476, 'negative naive bayes probablity': 0.8244998479596466})\n"
     ]
    }
   ],
   "source": [
    "#Task 10 explaination generator\n",
    "def explainator():\n",
    "    print(from_scratch_naive_bayes_with_explanation(\"horrible\"))\n",
    "explainator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taks 11. Pick two correctly and two incorrectly predicted tweet\n",
    "#pd.set_option('display.max_rows', None)\n",
    "#display(test_data_frame)\n",
    "'''\n",
    "False positive, should be neutral: @USAirways Good morning.\n",
    "By looking at the weighting of the word \"good\" and that this tweet is short, the word tips the tweet sentiment to \n",
    "positive. It should be neutral is i does not give any positive feedback, and is just saying hello.\n",
    "\n",
    "False neutral, should be positive: @united Great, thank you!! I'll send it now. \n",
    "My earlier explanation on this short tweet goes here, the few words that goes by the stop word sends it to natural \n",
    "on how the words weight on the occurance scale.\n",
    "\n",
    "True negative: @united I will but right now I'm to angry \n",
    "True negative: @united So disappointed in the service and the... \n",
    "Both of these contains words that are frequent negative, so it makes sense that they will be negative.\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
